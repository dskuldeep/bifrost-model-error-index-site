---
title: "model: meta-llama/Llama-3-70b-chat-hf"
provider: "anthropic"
provider_icon: "/logos/anthropic.svg"
solved: true
slug: "model-unavailable-error-9367"
---

## Reason

A 404 status error (`not_found_error`) when interacting with the Anthropic API indicates that the server could not locate the requested resource. When this error involves the model string `meta-llama/Llama-3-70b-chat-hf`, it is typically due to a mismatch between the provider and the model identifier.

Key reasons for this error include:
1. **Model Not Available**: The specific model identifier provided, `meta-llama/Llama-3-70b-chat-hf`, is a Meta Llama model. Anthropic's native API supports the Claude family of models (e.g., Claude 3.5 Sonnet, Claude 3 Opus) and does not host Llama models directly. Attempting to call the Anthropic endpoint with a non-native model ID results in a resource not found error.
2. **Resource Not Found**: The specific API resource or versioned endpoint you are attempting to access does not exist or has been deprecated.
3. **Incorrect API Endpoint**: You may be directed to an incorrect URL or utilizing a path that the server does not recognize as a valid endpoint for the requested operation.

## Solution
To resolve the 404 `not_found_error`, ensure that your request configuration aligns with Anthropic's supported models and endpoint structures. Follow these steps:
1. **Verify Model Availability and Naming**: Confirm that you are using a supported Anthropic model identifier. If you intend to use Anthropic's services, replace the Llama model ID with a valid Claude model ID, such as `claude-3-5-sonnet-20240620` or `claude-3-opus-20240229`. Refer to the Anthropic documentation for the current list of active model strings.
2. **Check API Endpoint**: Ensure your request is being sent to the correct base URL, typically `[REDACTED_URL] for the Messages API. If you are using a gateway or proxy, verify that the provider is correctly mapped to the model.
3. **Review Request URL**: Verify that the URL path is relative to the base API domain and does not contain extra segments or incorrect versioning prefixes that could lead to a 404.
4. **Check Provider Configuration**: If you are using a multi-model gateway (like Bifrost or AWS Bedrock), ensure that the provider selected matches the model ID. For instance, Llama models should be routed through providers like Meta, AWS Bedrock, or Hugging Face, not Anthropic.
5. **Contact Support**: If the configuration is correct but the error persists, contact Anthropic support. Provide the specific `request_id` found in the error response headers to help them diagnose the issue.

## Suggested Links
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
