---
title: "Invalid model stability:core. The model argument should be left blank."
provider: "openai"
provider_icon: "/logos/openai.svg"
solved: true
slug: "model-argument-error-9336"
---

## Reason

The `400 - Bad Request` error in the OpenAI API, specifically the message "Invalid model stability:core. The model argument should be left blank," typically indicates a mismatch between the API endpoint used and the parameters provided. This occurs for several reasons:
1. **Redundant Model Parameter**: For certain specialized endpoints or model wrappers (such as those for DALL-E 3 or Stability AI models routed through proxies), the model is implicitly defined by the endpoint. Providing an explicit `model` argument in the JSON body causes the request to be rejected.
2. **Incorrect or Expired API Keys**: An invalid or expired key prevents the server from processing the request, resulting in a generic 400 error.
3. **Invalid Request Parameters**: Parameters like `prompt`, `temperature`, or `max_tokens` may be missing or assigned the wrong data type (e.g., passing a string for a numeric field).
4. **Middleware and Client Configuration**: Misconfigured Axios instances, incorrect base URLs, or malformed `Authorization` headers can trigger this status code.
5. **Rate Limiting and Throttling**: Exceeding the predefined API usage limits for your tier will result in a 400 or 429 error.
6. **Model-Specific Constraints**: Using parameters unsupported by the target model (e.g., `dimensions` on a model that does not accept them) leads to validation failures.
7. **Environment Variable Issues**: Hidden characters, trailing spaces, or incorrect values in environment variables can cause silent request corruption.

## Solution
To resolve the `400 - Bad Request` error and address the invalid model argument, follow these steps:
1. **Remove the Model Argument**: If the error explicitly states the model argument should be left blank, remove the `"model": "..."` key-value pair from your API request body. This is often required for specific image generation or proxy-routed endpoints.
2. **Verify API Key**: Check that your API key is active and correctly formatted in your configuration.
3. **Validate Request Parameters**: Ensure all fields (like `prompt`, `n`, `size`) match the expected data types and required properties for the specific model being called.
4. **Inspect Client Configuration**: Review your Axios or fetch configuration to ensure the `baseURL` is correct and headers are properly structured.
5. **Check Rate Limits**: Review your OpenAI dashboard to ensure your account has sufficient credits and has not exceeded its usage limits.
6. **Align with Model Constraints**: Consult the documentation for the specific model (e.g., GPT-4 vs. DALL-E) to ensure every parameter used is supported.
7. **Audit Environment Variables**: Verify that variables like `OPENAI_API_KEY` do not contain hidden whitespace or newline characters.

## Suggested Links
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
