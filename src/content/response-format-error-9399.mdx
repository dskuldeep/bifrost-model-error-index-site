---
title: "'messages' must include 'json' to use 'response_format' as 'json_object'."
provider: "anyscale"
provider_icon: "/file.svg"
solved: true
slug: "response-format-error-9399"
---

## Raw Error Text

```text
'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'. (Request ID: Opk5awJuFf6KEcmLCeZx3-KHCkyXd5KhjGZ9xX2eiPk)
```

## Reason

The 400 status error from the Anyscale API occurs because the `response_format` parameter is set to `json_object`, but the input `messages` array lacks the explicit instruction required for the model to generate a valid JSON response. 

Key reasons for this failure include:
1. Missing 'json' Keyword: When JSON Mode is enabled, the API enforces a strict safety check requiring the word 'json' (case-insensitive) to appear in at least one of the messages (typically the system or user prompt). This ensures the model is primed to produce a parseable JSON structure.
2. Request Specification Mismatch: The API expects the `messages` array to be structured as a sequence of dictionaries where specific keywords or formats indicate that the model's output will be compatible with the `json_object` type.
3. Validation Failure: If the API cannot find a prompt-level instruction to output JSON, it rejects the request with a 400 Bad Request error to prevent potential non-JSON output that would fail client-side parsing.

## Solution
To resolve the 400 status error in the Anyscale API and successfully use JSON Mode, follow these remediation steps:
1. Update the Prompt Content: Ensure that the word 'json' is explicitly included in the `messages` array. You should add a clear instruction such as "Respond in JSON format" or "You are a helpful assistant that outputs JSON" within the system or user message content.
2. Structure the Messages Array: Format the `messages` parameter as a list of dictionaries. Each dictionary must represent a single message in the conversation.
3. Include Required Keys: Ensure every message dictionary contains the necessary `role` (e.g., 'system', 'user', or 'assistant') and `content` keys.
4. Verify API Specifications: Confirm that the message format complies with Anyscale's requirements for JSON Mode. This includes using a JSON-compatible structure and verifying that the model being called (such as Mistral or Llama-3 models hosted on Anyscale) supports the `json_object` response format.
5. Align Response Format: Double-check that `response_format` is correctly set to `{"type": "json_object"}` and that the prompt matches this expectation.

## Suggested Links
- [https://github.com/ray-project/ray/issues/31370](https://github.com/ray-project/ray/issues/31370)
- [https://github.com/langchain-ai/langchain/issues/15125](https://github.com/langchain-ai/langchain/issues/15125)
- [https://docs.apigee.com/api-platform/troubleshoot/runtime/400-decompressionfailureatrequest](https://docs.apigee.com/api-platform/troubleshoot/runtime/400-decompressionfailureatrequest)
- [https://learn.microsoft.com/vi-vn/azure/ai-services/openai/how-to/json-mode](https://learn.microsoft.com/vi-vn/azure/ai-services/openai/how-to/json-mode)
- [https://forum.bubble.io/t/how-to-catch-a-400-error-from-api-connector/27682](https://forum.bubble.io/t/how-to-catch-a-400-error-from-api-connector/27682)
- [https://community.openai.com/t/managing-messages-array-for-multi-user-chat-with-gpt-3-5-turbo/85976](https://community.openai.com/t/managing-messages-array-for-multi-user-chat-with-gpt-3-5-turbo/85976)
- [https://docs.anyscale.com/endpoints/fine-tuning/dataset-prep/](https://docs.anyscale.com/endpoints/fine-tuning/dataset-prep/)
- [https://docs.anyscale.com/endpoints/model-serving/json-mode/](https://docs.anyscale.com/endpoints/model-serving/json-mode/)
