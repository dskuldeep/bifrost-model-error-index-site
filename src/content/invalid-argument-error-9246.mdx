---
title: "Unrecognized request argument supplied: healthcheck"
provider: "openai"
provider_icon: "/logos/openai.png"
solved: true
slug: "invalid-argument-error-9246"
---

## Reason

The "Unrecognized request argument supplied: healthcheck" error is a specific instance of a 400 Bad Request error. It occurs when the OpenAI API receives a parameter in the JSON request body that is not part of the official schema for the endpoint being called.

Key reasons for this error include:
1. **Incorrect API Parameters**: The `healthcheck` parameter is not a valid argument for OpenAI API endpoints such as Chat Completions, Embeddings, or Images. OpenAI strictly validates all incoming keys and will reject the entire request if an unknown key is present.
2. **Middleware or Proxy Leakage**: This specific error often arises when using an API gateway, proxy, or monitoring wrapper. Parameters like `healthcheck` intended for the infrastructure layer are accidentally passed through to the OpenAI upstream server.
3. **Malformed Request Structure**: If the request syntax is incorrect or if parameters are placed at the wrong nesting level, the API may fail to recognize them, leading to a "Bad Request" response.
4. **Model-Specific Requirements**: Different models (e.g., `gpt-4o` vs `dall-e-3`) and endpoints have different acceptable parameters. Using a parameter supported by one model in a request to another that does not support it will trigger this error.

## Solution
To resolve the "Unrecognized request argument supplied" error, you must ensure your request payload strictly adheres to the OpenAI API specification. 

Follow these remediation steps:
1. **Identify and Remove Invalid Parameters**: Locate the `healthcheck` parameter in your code or request configuration and remove it. Ensure no other non-standard arguments are being sent in the request body.
2. **Review Official API Documentation**: Check the OpenAI API Reference for the specific endpoint you are using (e.g., `/v1/chat/completions`) to verify the exact names and types of all supported parameters.
3. **Verify Model Compatibility**: Ensure that every parameter used is compatible with the specific model targeted in your request. Some parameters are only available for newer models or specific modes (like JSON mode or Function Calling).
4. **Inspect Request Syntax**: Examine the structure of your JSON payload. If you are using a client SDK (like the OpenAI Python or Node.js libraries), ensure you are not passing extra keyword arguments that the library might inadvertently include in the API call.
5. **Check Infrastructure Configuration**: If you are using a proxy or a platform like Bifrost, verify that any management-related parameters are handled by the proxy and stripped before the request reaches OpenAI's servers.

## Suggested Links
- [https://platform.openai.com/docs/api-reference](https://platform.openai.com/docs/api-reference)
- [https://platform.openai.com/docs/guides/error-codes](https://platform.openai.com/docs/guides/error-codes)
