---
title: "Unsupported value: 'messages[0].role' does not support 'system' with this model."
provider: "openai"
provider_icon: "/logos/openai.svg"
solved: true
slug: "unsupported-value-error-9508"
---

## Reason

The error **"Unsupported value: 'messages[0].role' does not support 'system' with this model"** occurs because certain OpenAI models, specifically those in the **o1** reasoning family (such as `o1-preview` and `o1-mini`), do not support the standard `system` role in the messages array. This is due to the following factors:
1. **Model Architecture Limitations**: The initial versions of `o1-preview` and `o1-mini` were designed with a different internal instruction-following mechanism that does not recognize the `system` role as a valid input parameter.
2. **Invalid Role Specification**: OpenAI has introduced a new role, the `developer` role, intended to replace the `system` role for the **o1** family of models. Passing `system` to these models triggers a 400 Bad Request error because it is not part of the model's supported schema.
3. **Beta Status Restrictions**: As these models are in beta, they have stricter requirements for the `messages` array, typically requiring the conversation to start with a `user` message or a `developer` message rather than a `system` message.

## Solution
To resolve the unsupported role error, you must align your message configuration with the requirements of the **o1** series models. Follow these steps:
1. **Adopt the Developer Role**: For models like `o1-2024-12-17` and later, replace the `system` role with the `developer` role in your API request.
   - Example: `{"role": "developer", "content": "You are a helpful assistant."}`
2. **Fallback to User Role**: If you are using the earlier `o1-preview` or `o1-mini` versions that do not yet support the `developer` role, move your system instructions into the first `user` message.
3. **Use a Different Model**: If your application architecture strictly requires the `system` role and cannot be easily refactored, switch to a model that fully supports it, such as `gpt-4o` or `gpt-4-turbo`.
4. **Verify Model Documentation**: Check the latest OpenAI documentation for reasoning models to confirm supported roles, as capabilities (like streaming and role support) are updated frequently for the **o1** series.
5. **Check API Parameters**: Ensure you are also using `max_completion_tokens` instead of `max_tokens`, as reasoning models often require this specific parameter in conjunction with role changes.

## Suggested Links
- [https://cheatsheet.md/chatgpt-cheatsheet/openai-api-error-axioserror-request-failed-status-code-400](https://cheatsheet.md/chatgpt-cheatsheet/openai-api-error-axioserror-request-failed-status-code-400)
- [https://community.openai.com/t/o1-models-do-not-support-system-role-in-chat-completion/953880](https://community.openai.com/t/o1-models-do-not-support-system-role-in-chat-completion/953880)
- [https://community.openai.com/t/getting-400-response-with-already-working-code/509212](https://community.openai.com/t/getting-400-response-with-already-working-code/509212)
- [https://github.com/run-llama/llama_index/issues/17395](https://github.com/run-llama/llama_index/issues/17395)
- [https://community.openai.com/t/intermittent-error-an-unexpected-error-occurred-error-code-400-error-message-this-model-does-not-support-specifying-dimensions-type-invalid-request-error-param-none-code-none/955807](https://community.openai.com/t/intermittent-error-an-unexpected-error-occurred-error-code-400-error-message-this-model-does-not-support-specifying-dimensions-type-invalid-request-error-param-none-code-none/955807)
- [https://community.openai.com/t/request-failed-with-status-code-400/39242](https://community.openai.com/t/request-failed-with-status-code-400/39242)
- [https://platform.openai.com/docs/guides/reasoning](https://platform.openai.com/docs/guides/reasoning)
