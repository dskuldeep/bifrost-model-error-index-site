---
title: "Unsupported value: 'messages[0].role' does not support 'system' with this model."
provider: "openai"
provider_icon: "/logos/openai.svg"
solved: true
slug: "unsupported-value-error-9508"
---

## Reason

The error **"Unsupported value: 'messages[0].role' does not support 'system' with this model"** occurs because certain OpenAI models, specifically those in the **o1** reasoning family (such as `o1-preview` and `o1-mini`), do not support the standard `system` role in the messages array. This is due to the following factors:
1. **Model Architecture Limitations**: The initial versions of `o1-preview` and `o1-mini` were designed with a different internal instruction-following mechanism that does not recognize the `system` role as a valid input parameter.
2. **Invalid Role Specification**: OpenAI has introduced a new role, the `developer` role, intended to replace the `system` role for the **o1** family of models. Passing `system` to these models triggers a 400 Bad Request error because it is not part of the model's supported schema.
3. **Beta Status Restrictions**: As these models are in beta, they have stricter requirements for the `messages` array, typically requiring the conversation to start with a `user` message or a `developer` message rather than a `system` message.

## Solution
To resolve the unsupported role error, you must align your message configuration with the requirements of the **o1** series models. Follow these steps:
1. **Adopt the Developer Role**: For models like `o1-2024-12-17` and later, replace the `system` role with the `developer` role in your API request.
   - Example: `{"role": "developer", "content": "You are a helpful assistant."}`
2. **Fallback to User Role**: If you are using the earlier `o1-preview` or `o1-mini` versions that do not yet support the `developer` role, move your system instructions into the first `user` message.
3. **Use a Different Model**: If your application architecture strictly requires the `system` role and cannot be easily refactored, switch to a model that fully supports it, such as `gpt-4o` or `gpt-4-turbo`.
4. **Verify Model Documentation**: Check the latest OpenAI documentation for reasoning models to confirm supported roles, as capabilities (like streaming and role support) are updated frequently for the **o1** series.
5. **Check API Parameters**: Ensure you are also using `max_completion_tokens` instead of `max_tokens`, as reasoning models often require this specific parameter in conjunction with role changes.

## Suggested Links
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
- [Redacted URL](Redacted URL)
